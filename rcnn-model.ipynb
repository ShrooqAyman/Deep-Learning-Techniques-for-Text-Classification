{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:30:08.346540Z","iopub.execute_input":"2023-02-20T14:30:08.347348Z","iopub.status.idle":"2023-02-20T14:30:46.968513Z","shell.execute_reply.started":"2023-02-20T14:30:08.347202Z","shell.execute_reply":"2023-02-20T14:30:46.966893Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.14.0\n  latest version: 22.11.1\n\nPlease update conda by running\n\n    $ conda update -n base -c conda-forge conda\n\n\n\n# All requested packages already installed.\n\nRetrieving notices: ...working... done\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown --id 14mto87jQZLt4hTOcVV1H3wIyF1cvS4fS\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:30:46.969960Z","iopub.execute_input":"2023-02-20T14:30:46.970882Z","iopub.status.idle":"2023-02-20T14:30:50.055850Z","shell.execute_reply.started":"2023-02-20T14:30:46.970848Z","shell.execute_reply":"2023-02-20T14:30:50.054846Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/opt/conda/lib/python3.7/site-packages/gdown/cli.py:125: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=14mto87jQZLt4hTOcVV1H3wIyF1cvS4fS\nTo: /kaggle/working/glove.6B.50d.txt\n100%|████████████████████████████████████████| 171M/171M [00:02<00:00, 84.1MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, LSTM\nfrom keras.layers import Embedding\nfrom keras.layers import GRU\nfrom keras.layers import Conv1D, MaxPooling1D\nfrom keras.datasets import imdb\nfrom sklearn.datasets import fetch_20newsgroups\nimport numpy as np\nfrom sklearn import metrics\nfrom keras.preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-20T14:37:34.934277Z","iopub.execute_input":"2023-02-20T14:37:34.934737Z","iopub.status.idle":"2023-02-20T14:37:34.943044Z","shell.execute_reply.started":"2023-02-20T14:37:34.934689Z","shell.execute_reply":"2023-02-20T14:37:34.941950Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"newsgroups_train = fetch_20newsgroups(subset='train')\nnewsgroups_test = fetch_20newsgroups(subset='test')\nX_train = newsgroups_train.data\nX_test = newsgroups_test.data\ny_train = newsgroups_train.target\ny_test = newsgroups_test.target","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:30:52.803756Z","iopub.execute_input":"2023-02-20T14:30:52.804551Z","iopub.status.idle":"2023-02-20T14:30:53.205368Z","shell.execute_reply.started":"2023-02-20T14:30:52.804503Z","shell.execute_reply":"2023-02-20T14:30:53.203503Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n    np.random.seed(7)\n    text = np.concatenate((X_train, X_test), axis=0)\n    text = np.array(text)\n    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n    tokenizer.fit_on_texts(text)\n    sequences = tokenizer.texts_to_sequences(text)\n    word_index = tokenizer.word_index\n    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n    print('Found %s unique tokens.' % len(word_index))\n    indices = np.arange(text.shape[0])\n    # np.random.shuffle(indices)\n    text = text[indices]\n    print(text.shape)\n    X_train = text[0:len(X_train), ]\n    X_test = text[len(X_train):, ]\n    embeddings_index = {}\n    f = open(\"/kaggle/working/glove.6B.50d.txt\", encoding=\"utf8\")\n    for line in f:\n        values = line.split()\n        word = values[0]\n        try:\n            coefs = np.asarray(values[1:], dtype='float32')\n        except:\n            pass\n        embeddings_index[word] = coefs\n    f.close()\n    print('Total %s word vectors.' % len(embeddings_index))\n    return (X_train, X_test, word_index,embeddings_index)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:30:53.207651Z","iopub.execute_input":"2023-02-20T14:30:53.208070Z","iopub.status.idle":"2023-02-20T14:30:53.222032Z","shell.execute_reply.started":"2023-02-20T14:30:53.208034Z","shell.execute_reply":"2023-02-20T14:30:53.220409Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:30:53.224521Z","iopub.execute_input":"2023-02-20T14:30:53.225010Z","iopub.status.idle":"2023-02-20T14:31:34.259861Z","shell.execute_reply.started":"2023-02-20T14:30:53.224976Z","shell.execute_reply":"2023-02-20T14:31:34.258474Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 179209 unique tokens.\n(18846, 500)\nTotal 400000 word vectors.\n","output_type":"stream"}]},{"cell_type":"code","source":"def Build_Model_RCNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50):\n    kernel_size = 2\n    filters = 256\n    pool_size = 2\n    gru_node = 256\n    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            # words not found in embedding index will be all-zeros.\n            if len(embedding_matrix[i]) !=len(embedding_vector):\n                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n                exit(1)\n            embedding_matrix[i] = embedding_vector\n    model = Sequential()\n    model.add(Embedding(len(word_index) + 1,\n                                EMBEDDING_DIM,\n                                weights=[embedding_matrix],\n                                input_length=MAX_SEQUENCE_LENGTH,\n                                trainable=True))\n    model.add(Dropout(0.25))\n    model.add(Conv1D(filters, kernel_size, activation='relu'))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(Conv1D(filters, kernel_size, activation='relu'))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(Conv1D(filters, kernel_size, activation='relu'))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(Conv1D(filters, kernel_size, activation='relu'))\n    model.add(MaxPooling1D(pool_size=pool_size))\n    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n    model.add(LSTM(gru_node, recurrent_dropout=0.2))\n    model.add(Dense(1024,activation='relu'))\n    model.add(Dense(nclasses))\n    model.add(Activation('softmax'))\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    return model\n\nmodel_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:48.174711Z","iopub.execute_input":"2023-02-20T14:37:48.175155Z","iopub.status.idle":"2023-02-20T14:37:49.282567Z","shell.execute_reply.started":"2023-02-20T14:37:48.175116Z","shell.execute_reply":"2023-02-20T14:37:49.281297Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_RCNN.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:54.431438Z","iopub.execute_input":"2023-02-20T14:37:54.431872Z","iopub.status.idle":"2023-02-20T14:37:54.480718Z","shell.execute_reply.started":"2023-02-20T14:37:54.431840Z","shell.execute_reply":"2023-02-20T14:37:54.478629Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_1 (Embedding)     (None, 500, 50)           8960500   \n                                                                 \n dropout_1 (Dropout)         (None, 500, 50)           0         \n                                                                 \n conv1d_4 (Conv1D)           (None, 499, 256)          25856     \n                                                                 \n max_pooling1d_4 (MaxPooling  (None, 249, 256)         0         \n 1D)                                                             \n                                                                 \n conv1d_5 (Conv1D)           (None, 248, 256)          131328    \n                                                                 \n max_pooling1d_5 (MaxPooling  (None, 124, 256)         0         \n 1D)                                                             \n                                                                 \n conv1d_6 (Conv1D)           (None, 123, 256)          131328    \n                                                                 \n max_pooling1d_6 (MaxPooling  (None, 61, 256)          0         \n 1D)                                                             \n                                                                 \n conv1d_7 (Conv1D)           (None, 60, 256)           131328    \n                                                                 \n max_pooling1d_7 (MaxPooling  (None, 30, 256)          0         \n 1D)                                                             \n                                                                 \n lstm (LSTM)                 (None, 30, 256)           525312    \n                                                                 \n lstm_1 (LSTM)               (None, 30, 256)           525312    \n                                                                 \n lstm_2 (LSTM)               (None, 30, 256)           525312    \n                                                                 \n lstm_3 (LSTM)               (None, 256)               525312    \n                                                                 \n dense (Dense)               (None, 1024)              263168    \n                                                                 \n dense_1 (Dense)             (None, 20)                20500     \n                                                                 \n activation (Activation)     (None, 20)                0         \n                                                                 \n=================================================================\nTotal params: 11,765,256\nTrainable params: 11,765,256\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_RCNN.fit(X_train_Glove, y_train,\n                              validation_data=(X_test_Glove, y_test),\n                              epochs=15,\n                              batch_size=128,\n                              verbose=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:59.194199Z","iopub.execute_input":"2023-02-20T14:37:59.195475Z","iopub.status.idle":"2023-02-20T15:17:29.798898Z","shell.execute_reply.started":"2023-02-20T14:37:59.195381Z","shell.execute_reply":"2023-02-20T15:17:29.796927Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/15\n89/89 - 164s - loss: 2.6803 - accuracy: 0.1121 - val_loss: 2.3751 - val_accuracy: 0.1775 - 164s/epoch - 2s/step\nEpoch 2/15\n89/89 - 157s - loss: 2.1796 - accuracy: 0.2033 - val_loss: 2.0958 - val_accuracy: 0.2369 - 157s/epoch - 2s/step\nEpoch 3/15\n89/89 - 153s - loss: 1.8462 - accuracy: 0.3006 - val_loss: 1.7612 - val_accuracy: 0.3299 - 153s/epoch - 2s/step\nEpoch 4/15\n89/89 - 161s - loss: 1.5602 - accuracy: 0.4002 - val_loss: 1.6437 - val_accuracy: 0.3910 - 161s/epoch - 2s/step\nEpoch 5/15\n89/89 - 159s - loss: 1.2325 - accuracy: 0.5258 - val_loss: 1.6303 - val_accuracy: 0.4553 - 159s/epoch - 2s/step\nEpoch 6/15\n89/89 - 164s - loss: 1.0774 - accuracy: 0.5893 - val_loss: 1.2491 - val_accuracy: 0.5542 - 164s/epoch - 2s/step\nEpoch 7/15\n89/89 - 158s - loss: 0.8888 - accuracy: 0.6665 - val_loss: 1.1723 - val_accuracy: 0.6005 - 158s/epoch - 2s/step\nEpoch 8/15\n89/89 - 161s - loss: 0.7604 - accuracy: 0.7218 - val_loss: 1.1212 - val_accuracy: 0.6433 - 161s/epoch - 2s/step\nEpoch 9/15\n89/89 - 161s - loss: 0.6609 - accuracy: 0.7661 - val_loss: 1.0210 - val_accuracy: 0.6677 - 161s/epoch - 2s/step\nEpoch 10/15\n89/89 - 147s - loss: 0.5661 - accuracy: 0.8018 - val_loss: 1.0671 - val_accuracy: 0.6782 - 147s/epoch - 2s/step\nEpoch 11/15\n89/89 - 148s - loss: 0.4980 - accuracy: 0.8231 - val_loss: 1.0213 - val_accuracy: 0.6985 - 148s/epoch - 2s/step\nEpoch 12/15\n89/89 - 147s - loss: 0.4358 - accuracy: 0.8494 - val_loss: 1.0147 - val_accuracy: 0.7100 - 147s/epoch - 2s/step\nEpoch 13/15\n89/89 - 148s - loss: 0.3818 - accuracy: 0.8698 - val_loss: 1.0580 - val_accuracy: 0.7106 - 148s/epoch - 2s/step\nEpoch 14/15\n89/89 - 146s - loss: 0.3613 - accuracy: 0.8755 - val_loss: 1.0176 - val_accuracy: 0.7307 - 146s/epoch - 2s/step\nEpoch 15/15\n89/89 - 149s - loss: 0.2905 - accuracy: 0.9042 - val_loss: 1.1779 - val_accuracy: 0.7092 - 149s/epoch - 2s/step\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ff481376290>"},"metadata":{}}]},{"cell_type":"code","source":"predicted = model_RCNN.predict(X_test_Glove)\npredicted = np.argmax(predicted, axis=1)\nprint(metrics.classification_report(y_test, predicted))","metadata":{"execution":{"iopub.status.busy":"2023-02-20T15:22:22.587508Z","iopub.execute_input":"2023-02-20T15:22:22.588067Z","iopub.status.idle":"2023-02-20T15:22:55.034066Z","shell.execute_reply.started":"2023-02-20T15:22:22.588021Z","shell.execute_reply":"2023-02-20T15:22:55.032041Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"236/236 [==============================] - 32s 133ms/step\n              precision    recall  f1-score   support\n\n           0       0.51      0.62      0.56       319\n           1       0.48      0.70      0.57       389\n           2       0.73      0.64      0.68       394\n           3       0.54      0.73      0.62       392\n           4       0.58      0.65      0.61       385\n           5       0.76      0.66      0.71       395\n           6       0.77      0.73      0.75       390\n           7       0.68      0.83      0.75       396\n           8       0.96      0.66      0.78       398\n           9       0.86      0.84      0.85       397\n          10       0.97      0.91      0.94       399\n          11       0.90      0.80      0.84       396\n          12       0.53      0.54      0.54       393\n          13       0.89      0.80      0.84       396\n          14       0.89      0.71      0.79       394\n          15       0.80      0.81      0.81       398\n          16       0.66      0.79      0.72       364\n          17       0.95      0.74      0.83       376\n          18       0.86      0.38      0.53       310\n          19       0.34      0.48      0.40       251\n\n    accuracy                           0.71      7532\n   macro avg       0.73      0.70      0.71      7532\nweighted avg       0.74      0.71      0.72      7532\n\n","output_type":"stream"}]}]}