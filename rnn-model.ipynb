{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:27:22.487565Z","iopub.execute_input":"2023-02-20T08:27:22.488460Z","iopub.status.idle":"2023-02-20T08:30:28.238984Z","shell.execute_reply.started":"2023-02-20T08:27:22.488379Z","shell.execute_reply":"2023-02-20T08:30:28.238015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 14mto87jQZLt4hTOcVV1H3wIyF1cvS4fS\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:40:34.267225Z","iopub.execute_input":"2023-02-20T08:40:34.267574Z","iopub.status.idle":"2023-02-20T08:40:36.774234Z","shell.execute_reply.started":"2023-02-20T08:40:34.267536Z","shell.execute_reply":"2023-02-20T08:40:36.773267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dropout, Dense, GRU, Embedding\nfrom keras.models import Sequential\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nfrom sklearn import metrics\nfrom keras.preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences\nfrom sklearn.datasets import fetch_20newsgroups\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:40:37.041620Z","iopub.execute_input":"2023-02-20T08:40:37.041970Z","iopub.status.idle":"2023-02-20T08:40:42.889119Z","shell.execute_reply.started":"2023-02-20T08:40:37.041943Z","shell.execute_reply":"2023-02-20T08:40:42.888212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newsgroups_train = fetch_20newsgroups(subset='train')\nnewsgroups_test = fetch_20newsgroups(subset='test')\nX_train = newsgroups_train.data\nX_test = newsgroups_test.data\ny_train = newsgroups_train.target\ny_test = newsgroups_test.target","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:40:42.890627Z","iopub.execute_input":"2023-02-20T08:40:42.891157Z","iopub.status.idle":"2023-02-20T08:40:52.674962Z","shell.execute_reply.started":"2023-02-20T08:40:42.891131Z","shell.execute_reply":"2023-02-20T08:40:52.674069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n    np.random.seed(7)\n    text = np.concatenate((X_train, X_test), axis=0)\n    text = np.array(text)\n    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n    tokenizer.fit_on_texts(text)\n    sequences = tokenizer.texts_to_sequences(text)\n    word_index = tokenizer.word_index\n    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n    print('Found %s unique tokens.' % len(word_index))\n    indices = np.arange(text.shape[0])\n    # np.random.shuffle(indices)\n    text = text[indices]\n    print(text.shape)\n    X_train = text[0:len(X_train), ]\n    X_test = text[len(X_train):, ]\n    embeddings_index = {}\n    f = open(\"/kaggle/working/glove.6B.50d.txt\", encoding=\"utf8\")\n    for line in f:\n        values = line.split()\n        word = values[0]\n        try:\n            coefs = np.asarray(values[1:], dtype='float32')\n        except:\n            pass\n        embeddings_index[word] = coefs\n    f.close()\n    print('Total %s word vectors.' % len(embeddings_index))\n    return (X_train, X_test, word_index,embeddings_index)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:40:52.676521Z","iopub.execute_input":"2023-02-20T08:40:52.676809Z","iopub.status.idle":"2023-02-20T08:40:52.685752Z","shell.execute_reply.started":"2023-02-20T08:40:52.676785Z","shell.execute_reply":"2023-02-20T08:40:52.684636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:40:52.687403Z","iopub.execute_input":"2023-02-20T08:40:52.688072Z","iopub.status.idle":"2023-02-20T08:41:34.203945Z","shell.execute_reply.started":"2023-02-20T08:40:52.688022Z","shell.execute_reply":"2023-02-20T08:41:34.202100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Build_Model_RNN_Text(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n    \"\"\"\n    def buildModel_RNN(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n    word_index in word index ,\n    embeddings_index is embeddings index, \n    nClasses is number of classes,\n    MAX_SEQUENCE_LENGTH is maximum lenght of text sequences\n    \"\"\"\n    model = Sequential()\n    hidden_layer = 3\n    gru_node = 32\n    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            # words not found in embedding index will be all-zeros.\n            if len(embedding_matrix[i]) != len(embedding_vector):\n                print(\"could not broadcast input array from shape\", str(len(embedding_matrix[i])),\n                      \"into shape\", str(len(embedding_vector)), \" Please make sure your\"\n                                                                \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n                exit(1)\n            embedding_matrix[i] = embedding_vector\n    model.add(Embedding(len(word_index) + 1,\n                                EMBEDDING_DIM,\n                                weights=[embedding_matrix],\n                                input_length=MAX_SEQUENCE_LENGTH,\n                                trainable=True))\n    print(gru_node)\n    for i in range(0,hidden_layer):\n        model.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\n        model.add(Dropout(dropout))\n    model.add(GRU(gru_node, recurrent_dropout=0.2))\n    model.add(Dropout(dropout))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(nclasses, activation='softmax'))\n    model.compile(loss='sparse_categorical_crossentropy',\n                      optimizer='adam',\n                      metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:41:34.208807Z","iopub.execute_input":"2023-02-20T08:41:34.209121Z","iopub.status.idle":"2023-02-20T08:41:34.221445Z","shell.execute_reply.started":"2023-02-20T08:41:34.209097Z","shell.execute_reply":"2023-02-20T08:41:34.220138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_RNN = Build_Model_RNN_Text(word_index,embeddings_index, 20)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:41:34.222748Z","iopub.execute_input":"2023-02-20T08:41:34.223180Z","iopub.status.idle":"2023-02-20T08:41:35.561584Z","shell.execute_reply.started":"2023-02-20T08:41:34.223144Z","shell.execute_reply":"2023-02-20T08:41:35.560739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_RNN.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:51:03.047941Z","iopub.execute_input":"2023-02-20T08:51:03.048300Z","iopub.status.idle":"2023-02-20T08:51:03.079545Z","shell.execute_reply.started":"2023-02-20T08:51:03.048274Z","shell.execute_reply":"2023-02-20T08:51:03.078674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_RNN.fit(X_train_Glove, y_train,\n                              validation_data=(X_test_Glove, y_test),\n                              epochs=20,\n                              batch_size=128,\n                              verbose=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T08:51:06.302646Z","iopub.execute_input":"2023-02-20T08:51:06.303018Z","iopub.status.idle":"2023-02-20T09:35:30.907633Z","shell.execute_reply.started":"2023-02-20T08:51:06.302991Z","shell.execute_reply":"2023-02-20T09:35:30.906889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = model_RNN.predict(X_test_Glove)\nprint(metrics.classification_report(y_test,np.argmax(predicted,axis=1) ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}